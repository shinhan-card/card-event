"""
Universal Card Event Crawler
ì™„ì „ ìë™í™”ëœ ì§€ëŠ¥í˜• ì¹´ë“œì‚¬ ì´ë²¤íŠ¸ í¬ë¡¤ëŸ¬

ì£¼ìš” ê¸°ëŠ¥:
1. API ì¸í„°ì…‰íŠ¸ (JSON ì‘ë‹µ ìë™ ìº¡ì²˜)
2. ì§€ëŠ¥í˜• ìŠ¤í¬ë¡¤ (ë¬´í•œ ìŠ¤í¬ë¡¤ & ë”ë³´ê¸° ë²„íŠ¼ ìë™ ì²˜ë¦¬)
3. LLM ê¸°ë°˜ ë°ì´í„° ì •ì œ (Gemini API)
4. ì™„ì „ ìë™í™” ì‹¤í–‰ (ìˆ˜ë™ ê°œì… ë¶ˆí•„ìš”)
"""

import asyncio
import sys
import io
import json
import os
import random
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from playwright.async_api import async_playwright, Page, Browser, Response
from playwright_stealth import stealth_async
from bs4 import BeautifulSoup
from dotenv import load_dotenv
import google.generativeai as genai

# Windows ì½˜ì†” UTF-8 ì¸ì½”ë”©
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

load_dotenv()

# Gemini API ì„¤ì •
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))


class UniversalCardEventCrawler:
    """ë²”ìš© ì¹´ë“œì‚¬ ì´ë²¤íŠ¸ í¬ë¡¤ëŸ¬"""
    
    # ìµœì‹  Chrome User-Agent
    USER_AGENTS = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
    ]
    
    # ì¹´ë“œì‚¬ ì„¤ì •
    CARD_COMPANIES = {
        "ì‹ í•œì¹´ë“œ": {
            "url": "https://www.shinhancard.com/pconts/html/benefit/event/main.html",
            "domain": "shinhancard.com"
        },
        "ì‚¼ì„±ì¹´ë“œ": {
            "url": "https://www.samsungcard.com/personal/benefit/event/list.do",
            "domain": "samsungcard.com"
        },
        "í˜„ëŒ€ì¹´ë“œ": {
            "url": "https://www.hyundaicard.com/event/eventlist.hdc",
            "domain": "hyundaicard.com"
        },
        "KBêµ­ë¯¼ì¹´ë“œ": {
            "url": "https://www.kbcard.com/CRD/DVIEW/MBCXBDDAMBC0001.do",
            "domain": "kbcard.com"
        }
    }
    
    def __init__(self):
        self.browser: Browser = None
        self.page: Page = None
        self.intercepted_apis: List[Dict] = []
        self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
    
    async def init_browser(self, headless: bool = True):
        """Stealth ë¸Œë¼ìš°ì € ì´ˆê¸°í™”"""
        playwright = await async_playwright().start()
        
        launch_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-dev-shm-usage',
            '--disable-setuid-sandbox',
            '--no-first-run',
            '--no-default-browser-check',
            '--window-size=1920,1080',
        ]
        
        if headless:
            launch_args.extend(['--disable-gpu'])
        
        self.browser = await playwright.chromium.launch(
            headless=headless,
            args=launch_args
        )
        
        user_agent = random.choice(self.USER_AGENTS)
        
        context = await self.browser.new_context(
            user_agent=user_agent,
            viewport={'width': 1920, 'height': 1080},
            locale='ko-KR',
            timezone_id='Asia/Seoul',
            screen={'width': 1920, 'height': 1080},
        )
        
        # ìë™í™” íƒì§€ íšŒí”¼
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {get: () => undefined});
            window.chrome = {runtime: {}, loadTimes: function() {}, csi: function() {}};
            Object.defineProperty(navigator, 'plugins', {get: () => [1, 2, 3, 4, 5]});
            Object.defineProperty(navigator, 'languages', {get: () => ['ko-KR', 'ko', 'en-US']});
        """)
        
        self.page = await context.new_page()
        await stealth_async(self.page)
        
        print("[OK] Universal Crawler ì´ˆê¸°í™” ì™„ë£Œ (Stealth ëª¨ë“œ)\n")
    
    async def close_browser(self):
        """ë¸Œë¼ìš°ì € ì¢…ë£Œ"""
        if self.browser:
            await self.browser.close()
    
    # ==================== 1. API ì¸í„°ì…‰íŠ¸ ë¡œì§ ====================
    
    async def setup_api_interceptor(self, company_name: str):
        """
        API ì‘ë‹µ ì¸í„°ì…‰í„° ì„¤ì •
        - JSON ì‘ë‹µ ì¤‘ 'event', 'list' í‚¤ì›Œë“œ í¬í•¨ëœ ê²ƒ ìë™ ìº¡ì²˜
        - íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ë¶„ì„
        """
        print(f"[API ì¸í„°ì…‰í„°] {company_name} API ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
        
        async def handle_response(response: Response):
            """ì‘ë‹µ í•¸ë“¤ëŸ¬ (ê°œì„ ëœ í•„í„°ë§)"""
            try:
                url = response.url
                
                # 1ì°¨ í•„í„°: ì¹´ë“œì‚¬ ë„ë©”ì¸ í™•ì¸
                company_domain = self.CARD_COMPANIES[company_name]['domain']
                if company_domain not in url:
                    return  # ì™¸ë¶€ APIëŠ” ë¬´ì‹œ
                
                # 2ì°¨ í•„í„°: JSON ì‘ë‹µë§Œ
                content_type = response.headers.get('content-type', '')
                if 'application/json' not in content_type and 'json' not in content_type:
                    return
                
                # 3ì°¨ í•„í„°: URLì— ìœ ì˜ë¯¸í•œ í‚¤ì›Œë“œ í¬í•¨
                keywords = ['event', 'list', 'benefit', 'promotion', 'promo', 'card', 'data', 'info']
                if not any(kw in url.lower() for kw in keywords):
                    return
                
                # 4ì°¨ í•„í„°: ì œì™¸í•  URL íŒ¨í„´
                exclude_patterns = ['tracking', 'analytics', 'mpulse', 'log', 'metric', 'stat']
                if any(pattern in url.lower() for pattern in exclude_patterns):
                    return
                
                try:
                    json_data = await response.json()
                    
                    # 5ì°¨ í•„í„°: ìœ ì˜ë¯¸í•œ ë°ì´í„° í¬ê¸°
                    data_size = len(json.dumps(json_data))
                    if data_size < 100:  # ë„ˆë¬´ ì‘ìœ¼ë©´ ì˜ë¯¸ ì—†ìŒ
                        return
                    
                    # 6ì°¨ í•„í„°: ì´ë²¤íŠ¸ ê´€ë ¨ í‚¤ í¬í•¨ ì—¬ë¶€
                    json_str = json.dumps(json_data, ensure_ascii=False).lower()
                    event_indicators = ['title', 'name', 'ì œëª©', 'ì´ë²¤íŠ¸', 'event', 'benefit', 'í˜œíƒ']
                    
                    if any(indicator in json_str for indicator in event_indicators):
                        
                        self.intercepted_apis.append({
                            'company': company_name,
                            'url': url,
                            'data': json_data,
                            'timestamp': datetime.now().isoformat()
                        })
                        
                        print(f"  [API ìº¡ì²˜!] {url[:80]}...")
                        print(f"    ë°ì´í„° íƒ€ì…: {type(json_data).__name__}")
                        
                        if isinstance(json_data, list):
                            print(f"    ë°°ì—´ ê¸¸ì´: {len(json_data)}")
                        elif isinstance(json_data, dict):
                            print(f"    í‚¤ ê°œìˆ˜: {len(json_data.keys())}")
                        
                        print(f"    ë°ì´í„° í¬ê¸°: {data_size} bytes")
                        
                        # íŒŒì¼ë¡œ ì €ì¥
                        filename = f"api_captured_{company_name}_{len(self.intercepted_apis)}.json"
                        with open(filename, 'w', encoding='utf-8') as f:
                            json.dump(json_data, f, ensure_ascii=False, indent=2)
                        print(f"    ì €ì¥ë¨: {filename}\n")
                
                except Exception as e:
                    pass  # JSON íŒŒì‹± ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
            
            except Exception as e:
                pass  # ì¼ë°˜ ì˜¤ë¥˜ ë¬´ì‹œ
        
        # ì‘ë‹µ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
        self.page.on('response', handle_response)
        print(f"[OK] API ì¸í„°ì…‰í„° ì„¤ì • ì™„ë£Œ\n")
    
    # ==================== 2. ì§€ëŠ¥í˜• ìŠ¤í¬ë¡¤ & ë¡œë”© ëŒ€ê¸° ====================
    
    async def auto_scroll(self, max_scrolls: int = 20):
        """
        ìë™ ìŠ¤í¬ë¡¤ ë° ë™ì  ì½˜í…ì¸  ë¡œë”©
        - ë¬´í•œ ìŠ¤í¬ë¡¤ ê°ì§€
        - 'ë”ë³´ê¸°' ë²„íŠ¼ ìë™ í´ë¦­
        - í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
        """
        print("[ìë™ ìŠ¤í¬ë¡¤] í˜ì´ì§€ ì „ì²´ ë¡œë”© ì‹œì‘...")
        
        previous_height = 0
        scroll_count = 0
        
        while scroll_count < max_scrolls:
            # í˜„ì¬ í˜ì´ì§€ ë†’ì´ í™•ì¸
            current_height = await self.page.evaluate("document.body.scrollHeight")
            
            # í˜ì´ì§€ ëê¹Œì§€ ìŠ¤í¬ë¡¤
            await self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await asyncio.sleep(random.uniform(1.5, 2.5))
            
            # 'ë”ë³´ê¸°' ë²„íŠ¼ ì°¾ì•„ì„œ í´ë¦­
            more_buttons = [
                'button:has-text("ë”ë³´ê¸°")',
                'button:has-text("ë” ë³´ê¸°")',
                'a:has-text("ë”ë³´ê¸°")',
                '.more-btn',
                '.btn-more',
                'button.load-more',
                '[onclick*="more"]',
            ]
            
            for selector in more_buttons:
                try:
                    button = await self.page.query_selector(selector)
                    if button:
                        is_visible = await button.is_visible()
                        if is_visible:
                            print(f"  [ë°œê²¬!] 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­: {selector}")
                            await button.click()
                            await asyncio.sleep(random.uniform(2, 3))
                            break
                except:
                    continue
            
            # ìƒˆ ë†’ì´ í™•ì¸
            new_height = await self.page.evaluate("document.body.scrollHeight")
            
            # ë” ì´ìƒ ë³€í™”ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
            if new_height == previous_height:
                print(f"  [OK] ìŠ¤í¬ë¡¤ ì™„ë£Œ (ë†’ì´ ë³€í™” ì—†ìŒ)\n")
                break
            
            previous_height = new_height
            scroll_count += 1
            print(f"  ìŠ¤í¬ë¡¤ {scroll_count}íšŒ: ë†’ì´ {current_height} â†’ {new_height}")
        
        if scroll_count >= max_scrolls:
            print(f"  [OK] ìµœëŒ€ ìŠ¤í¬ë¡¤ íšŸìˆ˜ ë„ë‹¬ ({max_scrolls}íšŒ)\n")
        
        # í˜ì´ì§€ ìƒë‹¨ìœ¼ë¡œ ë³µê·€ (ì‚¬ëŒì²˜ëŸ¼)
        await self.page.evaluate("window.scrollTo(0, 0)")
        await asyncio.sleep(1)
    
    # ==================== 3. LLM ê¸°ë°˜ ë°ì´í„° ì •ì œ ====================
    
    def analyze_content_with_gemini(self, raw_content: str, company: str, url: str) -> Optional[Dict]:
        """
        Gemini APIë¡œ ë¹„êµ¬ì¡°í™” ë°ì´í„°ë¥¼ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
        
        Args:
            raw_content: JSON ë¬¸ìì—´ ë˜ëŠ” HTML í…ìŠ¤íŠ¸
            company: ì¹´ë“œì‚¬ëª…
            url: ì›ë³¸ URL
        
        Returns:
            dict: í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜ëœ ì´ë²¤íŠ¸ ë°ì´í„° ë˜ëŠ” None
        """
        if not raw_content or len(raw_content) < 50:
            return None
        
        system_prompt = """
ë‹¹ì‹ ì€ **ì¹´ë“œ ì‚°ì—… ì „ë¬¸ AI ì• ë„ë¦¬ìŠ¤íŠ¸**ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ë°ì´í„°(JSON ë˜ëŠ” í…ìŠ¤íŠ¸)ì—ì„œ ì¹´ë“œ ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥)**:
{
  "company": "ì¹´ë“œì‚¬ëª…",
  "category": "ì¹´í…Œê³ ë¦¬ (ì‡¼í•‘/ì—¬í–‰/ì‹ìŒë£Œ/êµí†µ/ë¬¸í™”/ìƒí™œ/ê¸ˆìœµ/í†µì‹ /ê¸°íƒ€)",
  "title": "ì´ë²¤íŠ¸ ì œëª©",
  "period": "ì´ë²¤íŠ¸ ê¸°ê°„ (YYYY.MM.DD~YYYY.MM.DD)",
  "benefit_type": "í˜œíƒ ìœ í˜• (í• ì¸/ìºì‹œë°±/í¬ì¸íŠ¸ì ë¦½/ë¬´ì´ìí• ë¶€/ì‚¬ì€í’ˆ/ê¸°íƒ€)",
  "benefit_value": "í˜œíƒ ê¸ˆì•¡/ë¹„ìœ¨ (ì˜ˆ: 10%, 5000ì›, ìµœëŒ€ 3ë§Œì›)",
  "conditions": "ì°¸ì—¬ ì¡°ê±´ ìš”ì•½",
  "target_segment": "íƒ€ê²Ÿ ê³ ê°ì¸µ",
  "threat_level": "ê²½ìŸ ìœ„í˜‘ë„ (High/Mid/Low)",
  "one_line_summary": "í•œ ì¤„ ìš”ì•½"
}

**ì¤‘ìš”**:
- ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥
- ì½”ë“œ ë¸”ë¡(```) ì‚¬ìš© ê¸ˆì§€
- ì •ë³´ ì—†ìœ¼ë©´ "ì •ë³´ ì—†ìŒ" í‘œê¸°
"""
        
        user_prompt = f"""
ì¹´ë“œì‚¬: {company}
URL: {url}

ì•„ë˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ í‘œì¤€ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•˜ì„¸ìš”:

{raw_content[:5000]}
"""
        
        try:
            print(f"  [Gemini] AI ë¶„ì„ ì¤‘... ({company})")
            
            response = self.gemini_model.generate_content(
                f"{system_prompt}\n\n{user_prompt}",
                generation_config={
                    "temperature": 0.2,
                    "top_p": 0.8,
                    "max_output_tokens": 1024,
                }
            )
            
            result_text = response.text.strip()
            
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            if result_text.startswith("```"):
                result_text = result_text.split("```")[1]
                if result_text.startswith("json"):
                    result_text = result_text[4:]
                result_text = result_text.strip()
            
            # JSON íŒŒì‹±
            parsed_data = json.loads(result_text)
            parsed_data["url"] = url
            parsed_data["raw_text"] = raw_content[:1000]
            
            print(f"  [OK] AI ë¶„ì„ ì™„ë£Œ: {parsed_data.get('title', 'ì œëª© ì—†ìŒ')}\n")
            
            return parsed_data
        
        except json.JSONDecodeError as e:
            print(f"  [WARN] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            print(f"  [ERROR] AI ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None
    
    # ==================== í•µì‹¬ í¬ë¡¤ë§ ë¡œì§ ====================
    
    async def crawl_company(self, company_name: str, config: Dict) -> List[Dict]:
        """
        ë‹¨ì¼ ì¹´ë“œì‚¬ í¬ë¡¤ë§ (ì™„ì „ ìë™í™”)
        
        Args:
            company_name: ì¹´ë“œì‚¬ëª…
            config: ì¹´ë“œì‚¬ ì„¤ì • (url, domain)
        
        Returns:
            list: ë¶„ì„ëœ ì´ë²¤íŠ¸ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        print("="*70)
        print(f"[{company_name}] í¬ë¡¤ë§ ì‹œì‘")
        print("="*70 + "\n")
        
        url = config['url']
        collected_events = []
        
        # API ì¸í„°ì…‰í„° ì„¤ì •
        self.intercepted_apis = []  # ì´ˆê¸°í™”
        await self.setup_api_interceptor(company_name)
        
        try:
            # í˜ì´ì§€ ë¡œë”©
            print(f"[í˜ì´ì§€ ë¡œë”©] {url}")
            await self.page.goto(url, wait_until="networkidle", timeout=60000)
            await asyncio.sleep(random.uniform(3, 5))
            
            # ì§€ëŠ¥í˜• ìë™ ìŠ¤í¬ë¡¤
            await self.auto_scroll(max_scrolls=10)
            
            # ì¶”ê°€ ëŒ€ê¸° (API ìš”ì²­ ì™„ë£Œ ëŒ€ê¸°)
            await asyncio.sleep(3)
            
            print(f"\n{'='*70}")
            print(f"[{company_name}] ìˆ˜ì§‘ ê²°ê³¼")
            print(f"{'='*70}\n")
            
            # 1ìˆœìœ„: API ì¸í„°ì…‰íŠ¸ ë°ì´í„° ì‚¬ìš©
            if self.intercepted_apis:
                print(f"[API ë°ì´í„°] {len(self.intercepted_apis)}ê°œ API ì‘ë‹µ ìº¡ì²˜ë¨")
                
                for i, api_data in enumerate(self.intercepted_apis, 1):
                    print(f"\n  [{i}/{len(self.intercepted_apis)}] API ë°ì´í„° ë¶„ì„ ì¤‘...")
                    
                    # JSONì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ Geminiì— ì „ë‹¬
                    json_str = json.dumps(api_data['data'], ensure_ascii=False, indent=2)
                    
                    # Geminië¡œ ë¶„ì„
                    analyzed = self.analyze_content_with_gemini(
                        json_str,
                        company_name,
                        api_data['url']
                    )
                    
                    if analyzed:
                        collected_events.append(analyzed)
                    
                    # API Rate Limit ë°©ì§€
                    if i < len(self.intercepted_apis):
                        await asyncio.sleep(2)
            
            # 2ìˆœìœ„: HTML íŒŒì‹±
            else:
                print(f"[HTML íŒŒì‹±] API ë°ì´í„° ì—†ìŒ, HTMLì—ì„œ ì¶”ì¶œ...")
                
                html = await self.page.content()
                soup = BeautifulSoup(html, 'lxml')
                
                # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
                for tag in soup(['script', 'style', 'nav', 'footer', 'header', 'aside']):
                    tag.decompose()
                
                # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                body = soup.find('body')
                if body:
                    text = body.get_text(separator='\n', strip=True)
                    text = '\n'.join([line.strip() for line in text.split('\n') if line.strip()])
                    
                    if len(text) > 200:
                        print(f"  [INFO] HTML í…ìŠ¤íŠ¸ ì¶”ì¶œ: {len(text)}ì")
                        
                        # Geminië¡œ ë¶„ì„
                        analyzed = self.analyze_content_with_gemini(
                            text[:8000],
                            company_name,
                            url
                        )
                        
                        if analyzed:
                            collected_events.append(analyzed)
            
            print(f"\n[{company_name}] ìˆ˜ì§‘ ì™„ë£Œ: {len(collected_events)}ê°œ ì´ë²¤íŠ¸\n")
            
            return collected_events
        
        except Exception as e:
            print(f"[ERROR] {company_name} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}\n")
            return []
    
    # ==================== 4. ì™„ì „ ìë™í™” ì‹¤í–‰ ====================
    
    async def run_all_sync(self) -> List[Dict]:
        """
        ì „ì²´ ì¹´ë“œì‚¬ ìë™ í¬ë¡¤ë§ (ìˆ˜ë™ ê°œì… ë¶ˆí•„ìš”)
        
        Returns:
            list: ëª¨ë“  ì¹´ë“œì‚¬ì˜ ì´ë²¤íŠ¸ ë°ì´í„°
        """
        print("\n" + "="*70)
        print("ğŸš€ Universal Card Event Crawler ì‹œì‘")
        print(f"   {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*70 + "\n")
        
        all_events = []
        
        # ë¸Œë¼ìš°ì € ì´ˆê¸°í™”
        await self.init_browser(headless=True)
        
        try:
            # ê° ì¹´ë“œì‚¬ ìˆœíšŒ
            for company_name, config in self.CARD_COMPANIES.items():
                events = await self.crawl_company(company_name, config)
                all_events.extend(events)
                
                # ë‹¤ìŒ ì¹´ë“œì‚¬ ì „ ëŒ€ê¸°
                if company_name != list(self.CARD_COMPANIES.keys())[-1]:
                    await asyncio.sleep(random.uniform(3, 5))
            
            # ìµœì¢… ê²°ê³¼
            print("\n" + "="*70)
            print("ğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ")
            print("="*70)
            print(f"  ì´ ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: {len(all_events)}ê°œ")
            
            # ì¹´ë“œì‚¬ë³„ í†µê³„
            company_stats = {}
            for event in all_events:
                comp = event.get('company', 'ì•Œ ìˆ˜ ì—†ìŒ')
                company_stats[comp] = company_stats.get(comp, 0) + 1
            
            print(f"\n  ì¹´ë“œì‚¬ë³„:")
            for comp, count in company_stats.items():
                print(f"    - {comp}: {count}ê°œ")
            
            print("="*70 + "\n")
            
            return all_events
        
        finally:
            await self.close_browser()
    
    # ==================== ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ====================
    
    async def run_and_save_to_db(self):
        """í¬ë¡¤ë§ + AI ë¶„ì„ + DB ì €ì¥ ì „ì²´ í”„ë¡œì„¸ìŠ¤"""
        from database import SessionLocal, insert_event
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        events = await self.run_all_sync()
        
        if not events:
            print("[WARN] ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        print("\n[DB ì €ì¥] ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
        db = SessionLocal()
        
        try:
            saved_count = 0
            duplicate_count = 0
            
            for i, event_data in enumerate(events, 1):
                print(f"  [{i}/{len(events)}] {event_data.get('title', 'ì œëª© ì—†ìŒ')}")
                
                success = insert_event(db, event_data)
                if success:
                    saved_count += 1
                else:
                    duplicate_count += 1
            
            print(f"\n[ì™„ë£Œ]")
            print(f"  ì‹ ê·œ ì €ì¥: {saved_count}ê°œ")
            print(f"  ì¤‘ë³µ ìŠ¤í‚µ: {duplicate_count}ê°œ")
            print(f"\n[INFO] ëŒ€ì‹œë³´ë“œ: http://localhost:8000\n")
        
        finally:
            db.close()


# ==================== ì‹¤í–‰ í•¨ìˆ˜ ====================

async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    crawler = UniversalCardEventCrawler()
    
    print("\n" + "="*70)
    print("Universal Card Event Crawler")
    print("="*70)
    print("\nì‹¤í–‰ ëª¨ë“œ:")
    print("  1. í¬ë¡¤ë§ë§Œ ì‹¤í–‰ (ê²°ê³¼ ì¶œë ¥)")
    print("  2. í¬ë¡¤ë§ + DB ì €ì¥ (ì „ì²´ íŒŒì´í”„ë¼ì¸)")
    print("  3. í…ŒìŠ¤íŠ¸ (ì‹ í•œì¹´ë“œë§Œ)")
    
    choice = input("\nì„ íƒ (1-3): ").strip()
    
    if choice == '1':
        # í¬ë¡¤ë§ë§Œ
        events = await crawler.run_all_sync()
        
        print("\nìˆ˜ì§‘ëœ ì´ë²¤íŠ¸:")
        for i, event in enumerate(events, 1):
            print(f"\n[{i}] {event.get('title')}")
            print(f"    íšŒì‚¬: {event.get('company')}")
            print(f"    ì¹´í…Œê³ ë¦¬: {event.get('category')}")
            print(f"    í˜œíƒ: {event.get('benefit_value')}")
            print(f"    ìœ„í˜‘ë„: {event.get('threat_level')}")
    
    elif choice == '2':
        # ì „ì²´ íŒŒì´í”„ë¼ì¸
        await crawler.run_and_save_to_db()
    
    elif choice == '3':
        # í…ŒìŠ¤íŠ¸ (ì‹ í•œì¹´ë“œë§Œ)
        await crawler.init_browser(headless=False)  # ë¸Œë¼ìš°ì € ë³´ì´ê²Œ
        
        try:
            test_company = "ì‹ í•œì¹´ë“œ"
            test_config = crawler.CARD_COMPANIES[test_company]
            
            events = await crawler.crawl_company(test_company, test_config)
            
            if events:
                print("\ní…ŒìŠ¤íŠ¸ ì„±ê³µ! ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸:")
                for event in events:
                    print(f"  - {event.get('title')}")
            else:
                print("\ní…ŒìŠ¤íŠ¸ ì™„ë£Œ. ìˆ˜ì§‘ëœ ì´ë²¤íŠ¸: 0ê°œ")
                print("ë¸Œë¼ìš°ì €ì™€ ì €ì¥ëœ JSON íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        finally:
            await crawler.close_browser()
    
    else:
        print("[ERROR] ì˜ëª»ëœ ì„ íƒ")


if __name__ == "__main__":
    asyncio.run(main())
